# 缓存

## 过期的数据的删除策略了解么

如果假设你设置了⼀批 key 只能存活 1 分钟，那么 1 分钟后，Redis 是怎么对这批 key 进⾏删除的呢？

常⽤的过期数据的删除策略就两个（重要！⾃⼰造缓存轮⼦的时候需要格外考虑的东⻄）：
1. 惰性删除 ：只会在取出key的时候才对数据进⾏过期检查。这样对CPU最友好，但是可能会
造成太多过期 key 没有被删除。
2. 定期删除 ： 每隔⼀段时间抽取⼀批 key 执⾏删除过期key操作。并且，Redis 底层会通过限
制删除操作执⾏的时⻓和频率来减少删除操作对CPU时间的影响。

定期删除对内存更加友好，惰性删除对CPU更加友好。两者各有千秋，所以Redis 采⽤的是 定期删除+惰性/懒汉式删除 。

但是，仅仅通过给 key 设置过期时间还是有问题的。因为还是可能存在定期删除和惰性删除漏掉了很多过期 key 的情况。这样就导致⼤量过期 key 堆积在内存⾥，然后就Out of memory了。

怎么解决这个问题呢？答案就是： Redis 内存淘汰机制。

## Redis 内存淘汰机制了解么？

Redis 提供 6 种数据淘汰策略：
1. volatile-lru（least recently used）：从已设置过期时间的数据集（server.db[i].expires）中挑选最近最少使⽤的数据淘汰
2. volatile-ttl：从已设置过期时间的数据集（server.db[i].expires）中挑选将要过期的数据淘汰
3. volatile-random：从已设置过期时间的数据集（server.db[i].expires）中任意选择数据淘汰
4. allkeys-lru（least recently used）：当内存不⾜以容纳新写⼊数据时，在键空间中，移除最近最少使⽤的 key（这个是最常⽤的）
5. allkeys-random：从数据集（server.db[i].dict）中任意选择数据淘汰
6. no-eviction：禁⽌驱逐数据，也就是说当内存不⾜以容纳新写⼊数据时，新写⼊操作会报错。这个应该没⼈使⽤吧！

4.0 版本后增加以下两种：
7. volatile-lfu（least frequently used）：从已设置过期时间的数据集(server.db[i].expires)中挑选最不经常使⽤的数据淘汰
8. allkeys-lfu（least frequently used）：当内存不⾜以容纳新写⼊数据时，在键空间中，移除最不经常使⽤的 key

## 缓存穿透

缓存穿透说简单点就是⼤量请求的 key 根本不存在于缓存中，导致请求直接到了数据库上，根本没有经过缓存这⼀层。举个例⼦：某个⿊客故意制造我们缓存中不存在的 key 发起⼤量请求，导致⼤量请求落到数据库。

### 有哪些解决办法

最基本的就是⾸先做好参数校验，⼀些不合法的参数请求直接抛出异常信息返回给客户端。⽐如查询的数据库 id 不能⼩于 0、传⼊的邮箱格式不对的时候直接返回错误消息给客户端等等。

#### 缓存⽆效 key

如果缓存和数据库都查不到某个 key 的数据就写⼀个到 Redis 中去并设置过期时间，具体命令如下： SET key value EX 10086 。这种⽅式可以解决请求的 key 变化不频繁的情况，如果⿊客恶意攻击，每次构建不同的请求 key，会导致 Redis 中缓存⼤量⽆效的 key 。很明显，这种⽅案并不能从根本上解决此问题。如果⾮要⽤这种⽅式来解决穿透问题的话，尽量将⽆效的 key 的过期时间设置短⼀点⽐如 1 分钟。

#### 布隆过滤器

布隆过滤器是⼀个⾮常神奇的数据结构，通过它我们可以⾮常⽅便地判断⼀个给定数据是否存在于海量数据中。我们需要的就是判断 key 是否合法，有没有感觉布隆过滤器就是我们想要找的那个“⼈”。

具体是这样做的：把所有可能存在的请求的值都存放在布隆过滤器中，当⽤户请求过来，先判断⽤户发来的请求的值是否存在于布隆过滤器中。不存在的话，直接返回请求参数错误信息给客户端，存在的话才会⾛下⾯的流程。

但是，需要注意的是布隆过滤器可能会存在误判的情况。总结来说就是： 布隆过滤器说某个元素存在，⼩概率会误判。布隆过滤器说某个元素不在，那么这个元素⼀定不在。

为什么会出现误判的情况呢? 我们还要从布隆过滤器的原理来说！

我们先来看⼀下，当⼀个元素加⼊布隆过滤器中的时候，会进⾏哪些操作：
1. 使⽤布隆过滤器中的哈希函数对元素值进⾏计算，得到哈希值（有⼏个哈希函数得到⼏个哈希值）。
2. 根据得到的哈希值，在位数组中把对应下标的值置为 1。

我们再来看⼀下，当我们需要判断⼀个元素是否存在于布隆过滤器的时候，会进⾏哪些操作：
1. 对给定元素再次进⾏相同的哈希计算；
2. 得到值之后判断位数组中的每个元素是否都为 1，如果值都为 1，那么说明这个值在布隆过滤器中，如果存在⼀个值不为 1，说明该元素不在布隆过滤器中。

然后，⼀定会出现这样⼀种情况：不同的字符串可能哈希出来的位置相同。 （可以适当增加位数组⼤⼩或者调整我们的哈希函数来降低概率）

https://github.com/Snailclimb/JavaGuide/blob/master/docs/dataStructures-algorithms/data-structure/bloom-filter.md

## 缓存雪崩

我发现缓存雪崩这名字起的有点意思，哈哈。

实际上，缓存雪崩描述的就是这样⼀个简单的场景：缓存在同⼀时间⼤⾯积的失效，后⾯的请求都直接落到了数据库上，造成数据库短时间内承受⼤量请求。 这就好⽐雪崩⼀样，摧枯拉朽之势，数据库的压⼒可想⽽知，可能直接就被这么多请求弄宕机了。

举个例⼦：系统的缓存模块出了问题⽐如宕机导致不可⽤。造成系统的所有访问，都要⾛数据库。

还有⼀种缓存雪崩的场景是：有⼀些被⼤量访问数据（热点缓存）在某⼀时刻⼤⾯积失效，导致对应的请求直接落到了数据库上。 这样的情况，有下⾯⼏种解决办法：

举个例⼦ ：秒杀开始 12 个⼩时之前，我们统⼀存放了⼀批商品到 Redis 中，设置的缓存过期时间也是 12 个⼩时，那么秒杀开始的时候，这些秒杀的商品的访问直接就失效了。导致的情况就是，相应的请求直接就落到了数据库上，就像雪崩⼀样可怕。

### 有哪些解决办法？

#### 针对 Redis 服务不可⽤的情况：

1. 采⽤ Redis 集群，避免单机出现问题整个缓存服务都没办法使⽤。
2. 限流，避免同时处理⼤量的请求。

#### 针对热点缓存失效的情况：

1. 设置不同的失效时间⽐如随机设置缓存的失效时间。
2. 缓存永不失效。

## 如何保证缓存和数据库数据的⼀致性？

这块作者写的不好

## Java高级面试里的应对缓存问题

穿透、击穿、雪崩
- 穿透：数据不存在（永远无法查到数据，每次落到数据库上，解决方案：1尝试设置无效标志位（默认值）代表数据不存在到redis，new Item(-1)）
- 击穿：同一数据击穿到数据库(缓存不存在，大量QPS都落到数据库上，1.增加消息组件，阻塞排队 2. 在java内部给item-id上锁(synchronize或retenLock)，先上锁的做mysql查询，可以把分布式的方案压缩成单体方案)
- 雪崩：不同的数据击穿到数据库（大量的key同一时间失效，1.redis.set(itemid,data,10_random())）

## Java高级面试里的应对缓存脏数据问题

- 脏读产生的原因
- 脏读如何避免

后台应用，消息给java引用，删key或更新

老师：脏读无法避免，只有二阶段提交能避免
只要使用了缓存，就无法避免脏读

脏读本质上无法避免

缓存必须要设置超时时间

## Java高级面试里的多级缓存

- 前台
    - H5页面，提前静态化好，CDN
- 中台
    - nginx（不建议）
        - proxy cache
        - lua
    - java（堆内堆外缓存）
- 后台
    - redis

越往前效率越高，但是更新越难